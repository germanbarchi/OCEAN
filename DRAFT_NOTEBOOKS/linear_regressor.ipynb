{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def split_train_test(df,merge_train_val,labels):\n",
    "    \n",
    "    df=df.drop(columns='audio_tag')\n",
    "    df_X=pd.concat([df.loc[:,'F0semitoneFrom27.5Hz_sma3nz_amean':'equivalentSoundLevel_dBp'],df.loc[:,'Partition']],axis=1)\n",
    "    \n",
    "    if not labels=='None':\n",
    "\n",
    "        df_Y=df.loc[:,['Partition',labels]]\n",
    "    else:\n",
    "        df_Y=pd.concat([df.loc[:,'extraversion':'openness'],df.loc[:,'Partition']],axis=1)\n",
    "\n",
    "    X_test=df_X[df_X['Partition']=='Test'].drop(columns='Partition')\n",
    "    Y_test=df_Y[df_Y['Partition']=='Test'].drop(columns='Partition')\n",
    "\n",
    "    X_train=df_X[df_X['Partition']=='Train'].drop(columns='Partition')\n",
    "    Y_train=df_Y[df_Y['Partition']=='Train'].drop(columns='Partition')\n",
    "\n",
    "    X_val=df_X[df_X['Partition']=='Val'].drop(columns='Partition')\n",
    "    Y_val=df_Y[df_Y['Partition']=='Val'].drop(columns='Partition')     \n",
    "\n",
    "    if merge_train_val=='True':\n",
    "        X_train=X_train.append(X_val)\n",
    "        Y_train=Y_train.append(Y_val)\n",
    "    \n",
    "    return X_test,Y_test,X_train,Y_train,X_val,Y_val\n",
    "\n",
    "def RandomForest(df,labels,merge_val_train):  \n",
    "    \n",
    "    X_test, Y_test, X_train, Y_train, X_val,Y_val =split_train_test(df,merge_val_train,labels)\n",
    "    \n",
    "    RF_reg=LinearRegression() \n",
    "    \n",
    "    RF_reg.fit(X_train,Y_train)\n",
    "      \n",
    "    predictions=RF_reg.predict(X_val.values)\n",
    "      \n",
    "    r2=r2_score(Y_val, predictions)    \n",
    "    \n",
    "    MAE=mean_absolute_error(Y_val, predictions)\n",
    "    MSE=mean_squared_error(Y_val, predictions)\n",
    "    RMSE=np.sqrt(mean_squared_error(Y_val, predictions))\n",
    "        \n",
    "    return predictions,r2,MAE,MSE,RMSE,Y_val, RF_reg\n",
    "\n",
    "def resumen(results_path,var):\n",
    "    \n",
    "    big_five=['all','O','C','E','A','N']\n",
    "\n",
    "    DF_final=pd.DataFrame()\n",
    "    DF_final['index']=['r2','r','MAE','MSE','RMSE']\n",
    "    DF_final=DF_final.set_index('index')    \n",
    "\n",
    "    for dim in big_five:\n",
    "        DF_final[dim]=np.array([var['r2_'+dim],np.sqrt(var['r2_'+dim]),var['MAE_'+dim],var['MSE_'+dim],var['RMSE_'+dim]])\n",
    "    \n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "\n",
    "    #DF_final.to_csv(results_path+'/performance.csv')\n",
    "    return DF_final\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \n",
    "    df_path=sys.argv[1]\n",
    "    merge_val_train='False' #False: no mergeo train y val \n",
    "    #save_path=sys.argv[3]\n",
    "    experiment_name=sys.argv[4]\n",
    "\n",
    "    results_path=save_path+'/data/'+experiment_name\n",
    "\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "\n",
    "    df=pd.read_csv(df_path)   \n",
    "    df=df.fillna(0)\n",
    "    warnings.filterwarnings('ignore')\n",
    "    labels='None'\n",
    "    print('Predicción Random Forest con labels OCEAN')\n",
    "    preds_all,r2_all,MAE_all,MSE_all,RMSE_all,y_test,RF_reg=RandomForest(df, labels,merge_val_train)\n",
    "    \n",
    "    print('Predicción Random Forest con label OPENNESS')\n",
    "    labels='openness' \n",
    "    preds_O,r2_O,MAE_O,MSE_O,RMSE_O,y_test_O,RF_reg_O=RandomForest(df, labels, merge_val_train)\n",
    "    \n",
    "    print('Predicción Random Forest con label CONSCIENCIOUSNESS')\n",
    "    labels='conscientiousness' \n",
    "    preds_C,r2_C,MAE_C,MSE_C,RMSE_C,y_test_C,RF_reg_C=RandomForest(df, labels, merge_val_train)    \n",
    "    \n",
    "    print('Predicción Random Forest con label EXTRAVERSION')\n",
    "    labels='extraversion' \n",
    "    preds_E,r2_E,MAE_E,MSE_E,RMSE_E,y_test_E,RF_reg_E=RandomForest(df, labels, merge_val_train)\n",
    "    \n",
    "    print('Predicción Random Forest con label AGREEABLENESS')\n",
    "    labels='agreeableness' \n",
    "    preds_A,r2_A,MAE_A,MSE_A,RMSE_A,y_test_A,RF_reg_A=RandomForest(df, labels, merge_val_train)\n",
    "    \n",
    "    print('Predicción Random Forest con label NEUROTICISM')\n",
    "    labels='neuroticism' \n",
    "    preds_N,r2_N,MAE_N,MSE_N,RMSE_N,y_test_N,RF_reg_N=RandomForest(df, labels, merge_val_train)\n",
    "\n",
    "    print('Guardando datos en %s' % results_path)\n",
    "    \n",
    "    var=vars()\n",
    "    resumen(results_path,var)\n",
    "\n",
    "    importance_O=RF_reg_O.feature_importances_\n",
    "    importance_C=RF_reg_C.feature_importances_\n",
    "    importance_E=RF_reg_E.feature_importances_\n",
    "    importance_A=RF_reg_A.feature_importances_\n",
    "    importance_N=RF_reg_N.feature_importances_   \n",
    "\n",
    "       \n",
    "    # Importance\n",
    "\n",
    "    features_list=list(df.loc[:,~df.columns.isin(['Partition','audio_tag','extraversion','conscientiousness','openness','agreeableness','neuroticism'])].columns[1:])\n",
    "    \n",
    "    importance_DF=pd.DataFrame({'O':importance_O,'C':importance_C,'E':importance_E,'A':importance_A,'N':importance_N})\n",
    "    importance_DF['features']=features_list\n",
    "\n",
    "    importance_DF.to_csv(results_path+'/importance.csv')\n",
    "\n",
    "    # Busqueda de los features más importantes\n",
    "    \n",
    "    importance_DF=pd.melt(importance_DF,id_vars=['features'],value_vars=['O','C','E','A','N']).rename(columns={'variable':'Personality','value':'Importance'})\n",
    "    percentil_95=np.percentile(importance_DF.Importance.values,95)\n",
    "    relevant_features_DF=importance_DF[importance_DF['Importance']>percentil_95]\n",
    "\n",
    "    relevant_features_DF.to_csv(results_path+'/relevant_features.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d29ee2a6b024b3ef0af2f29a3df7b0f54a5cbf6eee460d08c8941f471b385dbe"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
